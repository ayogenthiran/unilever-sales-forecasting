{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10268756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ---- Metrics (fixed) ----\n",
    "def wmape(y_true, y_pred, eps=1e-9):\n",
    "    denom = max(np.abs(y_true).sum(), eps)\n",
    "    return np.abs(y_true - y_pred).sum() / denom\n",
    "\n",
    "def accuracy_from_wmape(w):  # convenience\n",
    "    return 1.0 - w\n",
    "\n",
    "def bias(y_true, y_pred, eps=1e-9):\n",
    "    pred_sum = max(np.abs(y_pred).sum(), eps)\n",
    "    return (np.abs(y_true).sum() / pred_sum) - 1.0\n",
    "\n",
    "def print_metrics(y_true, y_pred, label=\"\"):\n",
    "    w = wmape(y_true, y_pred)\n",
    "    b = bias(y_true, y_pred)\n",
    "    print(f\"{label} WMAPE: {w:.4f} | Accuracy: {1-w:.4f} | Bias: {b:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a97b1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (143273, 20)\n",
      "Keys: 970 | Weeks: 2020-01 → 2023-03\n",
      "Zero %: 56.21505796626022\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sales_pred_case/sales_pred_case.csv') # adjust if needed\n",
    "\n",
    "\n",
    "# Types\n",
    "df['YearWeek'] = df['YearWeek'].astype(str)\n",
    "df['Key'] = df['Key'].astype(str)\n",
    "df['Sales'] = df['Sales'].astype(float)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Keys:\", df['Key'].nunique(), \"| Weeks:\", df['YearWeek'].min(), \"→\", df['YearWeek'].max())\n",
    "print(\"Zero %:\", (df['Sales']==0).mean()*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10e03ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid weeks: ['2022-41', '2022-42', '2022-43', '2022-44', '2022-45']\n",
      "Pred weeks : ['2022-46', '2022-47', '2022-48', '2022-49', '2022-50', '2022-51', '2022-52', '2023-01', '2023-02']\n"
     ]
    }
   ],
   "source": [
    "# Exact prediction window (9 weeks)\n",
    "PRED_WEEKS = [f\"2022-{w:02d}\" for w in range(46, 53)] + [f\"2023-{w:02d}\" for w in range(1, 3)]\n",
    "CUTOFF_TRAIN = \"2022-45\"\n",
    "VALID_WEEKS = [f\"2022-{w:02d}\" for w in range(41, 46)]\n",
    "\n",
    "def add_time_index(d):\n",
    "    d = d.copy()\n",
    "    year = d['YearWeek'].str[:4].astype(int)\n",
    "    week = d['YearWeek'].str[5:7].astype(int)\n",
    "    d['yw_index'] = (year - year.min()) * 60 + week\n",
    "    return d\n",
    "\n",
    "df = add_time_index(df)\n",
    "print(\"Valid weeks:\", VALID_WEEKS)\n",
    "print(\"Pred weeks :\", PRED_WEEKS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47db2abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FEATURE ENGINEERING (leak-safe)\n",
      "==================================================\n",
      "After FE: (143273, 48)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"FEATURE ENGINEERING (leak-safe)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "dfe = df.sort_values(['Key','yw_index']).copy()\n",
    "\n",
    "# Calendar helpers from existing cols (already provided)\n",
    "# We keep: Week, Month, Qtr, holidays, price, promo, objectives, etc.\n",
    "\n",
    "# Lags\n",
    "LAGS = (1,2,3,4,8,12,26,52)\n",
    "def make_lags(g):\n",
    "    g = g.sort_values('yw_index').copy()\n",
    "    for L in LAGS:\n",
    "        g[f'Sales_lag_{L}'] = g['Sales'].shift(L)\n",
    "    return g\n",
    "\n",
    "dfe = dfe.groupby('Key', group_keys=False).apply(make_lags)\n",
    "\n",
    "# Rolling stats on shifted sales (no leakage)\n",
    "ROLLS = (3,8,12,26)\n",
    "def make_rolls(g):\n",
    "    g = g.sort_values('yw_index').copy()\n",
    "    s = g['Sales'].shift(1)\n",
    "    for W in ROLLS:\n",
    "        g[f'Sales_rollmean_{W}'] = s.rolling(W, min_periods=2).mean()\n",
    "        g[f'Sales_rollstd_{W}']  = s.rolling(W, min_periods=2).std()\n",
    "    return g\n",
    "\n",
    "dfe = dfe.groupby('Key', group_keys=False).apply(make_rolls)\n",
    "\n",
    "# EWM on shifted sales\n",
    "def make_ewm(g):\n",
    "    g = g.sort_values('yw_index').copy()\n",
    "    s = g['Sales'].shift(1)\n",
    "    g['Sales_ewm_4'] = s.ewm(span=4).mean()\n",
    "    g['Sales_ewm_8'] = s.ewm(span=8).mean()\n",
    "    return g\n",
    "\n",
    "dfe = dfe.groupby('Key', group_keys=False).apply(make_ewm)\n",
    "\n",
    "# Growth rates from lags (no current value)\n",
    "dfe['Sales_growth_1'] = (dfe['Sales_lag_1'] - dfe['Sales_lag_2']) / (dfe['Sales_lag_2'].replace(0, np.nan))\n",
    "dfe['Sales_growth_4'] = (dfe['Sales_lag_1'] - dfe['Sales_lag_4']) / (dfe['Sales_lag_4'].replace(0, np.nan))\n",
    "dfe[['Sales_growth_1','Sales_growth_4']] = dfe[['Sales_growth_1','Sales_growth_4']].replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "# Interactions\n",
    "dfe['DiscountedPrice_x_PromoShipment'] = dfe['DiscountedPrice'] * dfe['PromoShipment']\n",
    "dfe['Holiday_sum'] = dfe['New_Year'] + dfe['Christmas_Day'] + dfe['Easter_Monday'] + dfe['Other_Holidays']\n",
    "dfe['Is_Holiday'] = (dfe['Holiday_sum'] > 0).astype(int)\n",
    "\n",
    "# Key-level stats (safe: computed from entire history, small leakage risk but static)\n",
    "key_stats = dfe.groupby('Key')['Sales'].agg(['mean','std','min','max']).add_prefix('Key_')\n",
    "dfe = dfe.merge(key_stats, left_on='Key', right_index=True, how='left')\n",
    "\n",
    "print(\"After FE:\", dfe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9353676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train weeks: 2020-53 → 2022-45\n",
      "Valid weeks: ['2022-41', '2022-42', '2022-43', '2022-44', '2022-45']\n",
      "Pred weeks : ['2022-46', '2022-47', '2022-48', '2022-49', '2022-50', '2022-51', '2022-52', '2023-01', '2023-02']\n",
      "Features  : 44\n"
     ]
    }
   ],
   "source": [
    "def split_weeks(d):\n",
    "    train = d[d['YearWeek'] <= CUTOFF_TRAIN].copy()\n",
    "    valid = d[d['YearWeek'].isin(VALID_WEEKS)].copy()\n",
    "    testp = d[d['YearWeek'].isin(PRED_WEEKS)].copy()\n",
    "    return train, valid, testp\n",
    "\n",
    "train, valid, testp = split_weeks(dfe)\n",
    "\n",
    "# Drop rows without required history\n",
    "train = train.dropna(subset=[c for c in train.columns if c.startswith('Sales_lag_')])\n",
    "\n",
    "BASE_FEATS = [\n",
    "    'Material','Customer','CustomerGroup','Category',\n",
    "    'Week','Month','Qtr',\n",
    "    'New_Year','Christmas_Day','Easter_Monday','Other_Holidays',\n",
    "    'DiscountedPrice','PromoShipment','Objective1','Objective2','PromoMethod','PromoStatus',\n",
    "    'DiscountedPrice_x_PromoShipment','Is_Holiday','Holiday_sum',\n",
    "    'Key_mean','Key_std','Key_min','Key_max'\n",
    "]\n",
    "LAG_FEATS  = [c for c in dfe.columns if c.startswith('Sales_lag_')]\n",
    "ROLL_FEATS = [c for c in dfe.columns if c.startswith('Sales_roll')]\n",
    "EWM_FEATS  = ['Sales_ewm_4','Sales_ewm_8']\n",
    "GRW_FEATS  = ['Sales_growth_1','Sales_growth_4']\n",
    "\n",
    "FEATS = BASE_FEATS + LAG_FEATS + ROLL_FEATS + EWM_FEATS + GRW_FEATS\n",
    "\n",
    "print(\"Train weeks:\", train['YearWeek'].min(), \"→\", train['YearWeek'].max())\n",
    "print(\"Valid weeks:\", sorted(valid['YearWeek'].unique()))\n",
    "print(\"Pred weeks :\", sorted(testp['YearWeek'].unique()))\n",
    "print(\"Features  :\", len(FEATS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9326b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttrain's l1: 131.248\tvalid's l1: 165.584\n",
      "[400]\ttrain's l1: 127.82\tvalid's l1: 162.415\n",
      "[600]\ttrain's l1: 125.153\tvalid's l1: 159.392\n",
      "[800]\ttrain's l1: 122.785\tvalid's l1: 156.777\n",
      "[1000]\ttrain's l1: 120.734\tvalid's l1: 154.275\n",
      "[1200]\ttrain's l1: 118.725\tvalid's l1: 151.707\n",
      "[1400]\ttrain's l1: 117.138\tvalid's l1: 149.99\n",
      "[1600]\ttrain's l1: 115.771\tvalid's l1: 148.339\n",
      "[1800]\ttrain's l1: 114.453\tvalid's l1: 146.739\n",
      "[2000]\ttrain's l1: 113.414\tvalid's l1: 145.525\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's l1: 113.414\tvalid's l1: 145.525\n",
      "Validation (2022-41..45) WMAPE: 0.5472 | Accuracy: 0.4528 | Bias: 0.2748\n",
      "LGBM+Baseline (20% key-avg + 80% model) WMAPE: 0.5608 | Accuracy: 0.4392 | Bias: 0.2110\n"
     ]
    }
   ],
   "source": [
    "X_tr = train[FEATS].copy()\n",
    "y_tr = train['Sales'].values\n",
    "X_va = valid[FEATS].copy()\n",
    "y_va = valid['Sales'].values\n",
    "\n",
    "# Fill remaining NaNs (from std/growth early periods)\n",
    "X_tr = X_tr.fillna(0.0)\n",
    "X_va = X_va.fillna(0.0)\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective='mae',      # L1 to align with WMAPE\n",
    "    metric='mae',\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=128,\n",
    "    learning_rate=0.02,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    min_data_in_leaf=50,\n",
    "    lambda_l1=0.1,\n",
    "    lambda_l2=0.1,\n",
    "    verbose=-1,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
    "dvalid = lgb.Dataset(X_va, label=y_va, reference=dtrain)\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    dtrain,\n",
    "    valid_sets=[dtrain, dvalid],\n",
    "    valid_names=['train','valid'],\n",
    "    num_boost_round=2000,\n",
    "    callbacks=[lgb.early_stopping(150), lgb.log_evaluation(200)]\n",
    ")\n",
    "\n",
    "va_pred = lgb_model.predict(X_va)\n",
    "print_metrics(y_va, va_pred, \"Validation (2022-41..45)\")\n",
    "\n",
    "# ---- Baseline blend (safe, time-ordered, no leakage) ----\n",
    "alpha = 0.2  # 20% baseline, 80% model\n",
    "\n",
    "# Ensure training data is sorted by time so \"tail(4)\" is truly the latest 4 per key\n",
    "train_sorted = train.sort_values(['Key', 'yw_index'])\n",
    "\n",
    "# Per-key average of the last 4 observed weeks in TRAIN (≤ 2022-45)\n",
    "last4wk = train_sorted.groupby('Key')['Sales'].apply(lambda s: s.tail(4).mean())\n",
    "\n",
    "# Map baseline to the validation rows by Key\n",
    "baseline = valid['Key'].map(last4wk).astype(float).fillna(0.0).values\n",
    "\n",
    "# Blend baseline with the LGB predictions\n",
    "blended = alpha * baseline + (1.0 - alpha) * va_pred\n",
    "print_metrics(y_va, blended, \"LGBM+Baseline (20% key-avg + 80% model)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25233776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RF WMAPE: 0.5360 | Accuracy: 0.4640 | Bias: 0.0097\n",
      "Best ensemble weights (LGB, RF): (0.5, 0.5) | WMAPE: 0.5387\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=16,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt',\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED\n",
    ")\n",
    "rf.fit(X_tr, y_tr)\n",
    "va_pred_rf = rf.predict(X_va)\n",
    "\n",
    "print_metrics(y_va, va_pred_rf, \"Validation RF\")\n",
    "\n",
    "# Grid of weights; here we MINIMIZE WMAPE (not maximize)\n",
    "candidates = [(0.9,0.1),(0.8,0.2),(0.7,0.3),(0.6,0.4),(0.5,0.5)]\n",
    "best = (None, 1e9)\n",
    "for w_lgb, w_rf in candidates:\n",
    "    blend = w_lgb*va_pred + w_rf*va_pred_rf\n",
    "    w = wmape(y_va, blend)\n",
    "    if w < best[1]:\n",
    "        best = ((w_lgb, w_rf), w)\n",
    "best_weights, best_wmape = best\n",
    "print(f\"Best ensemble weights (LGB, RF): {best_weights} | WMAPE: {best_wmape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1df966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast rows: (8730, 4)\n",
      "Weeks covered: ['2022-46' '2022-47' '2022-48' '2022-49' '2022-50' '2022-51' '2022-52'\n",
      " '2023-01' '2023-02']\n"
     ]
    }
   ],
   "source": [
    "# Retrain on all data up to cutoff\n",
    "full_hist = dfe[dfe['YearWeek'] <= CUTOFF_TRAIN].copy()\n",
    "full_hist = full_hist.dropna(subset=[c for c in full_hist.columns if c.startswith('Sales_lag_')])\n",
    "\n",
    "X_full = full_hist[FEATS].fillna(0.0)\n",
    "y_full = full_hist['Sales'].values\n",
    "\n",
    "final_lgb = lgb.train(lgb_params, lgb.Dataset(X_full, label=y_full), num_boost_round=lgb_model.best_iteration or 1000)\n",
    "\n",
    "# If using the ensemble:\n",
    "use_rf = True\n",
    "if use_rf:\n",
    "    final_rf = RandomForestRegressor(\n",
    "        n_estimators=rf.n_estimators,\n",
    "        max_depth=rf.max_depth,\n",
    "        min_samples_split=rf.min_samples_split,\n",
    "        min_samples_leaf=rf.min_samples_leaf,\n",
    "        max_features=rf.max_features,\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    final_rf.fit(X_full, y_full)\n",
    "\n",
    "# Make a working copy we can roll forward\n",
    "work = df.copy()\n",
    "work = add_time_index(work)\n",
    "work = work.sort_values(['Key','yw_index'])\n",
    "work = work.groupby('Key', group_keys=False).apply(make_lags)\n",
    "work = work.groupby('Key', group_keys=False).apply(make_rolls)\n",
    "work = work.groupby('Key', group_keys=False).apply(make_ewm)\n",
    "\n",
    "preds = []\n",
    "for wk in PRED_WEEKS:\n",
    "    step = work[work['YearWeek'] == wk].copy()\n",
    "\n",
    "    # Build feature frame for this step\n",
    "    # We need all engineered columns; recompute helper cols that depend on lagged sales already in `work`\n",
    "    step = step.merge(\n",
    "        dfe[['Key','YearWeek'] + BASE_FEATS].drop_duplicates(),\n",
    "        on=['Key','YearWeek'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Ensure all FEATS exist\n",
    "    for c in FEATS:\n",
    "        if c not in step.columns:\n",
    "            step[c] = np.nan\n",
    "\n",
    "    X_step = step[FEATS].fillna(0.0)\n",
    "    yhat_lgb = final_lgb.predict(X_step)\n",
    "    if use_rf:\n",
    "        yhat_rf = final_rf.predict(X_step)\n",
    "        yhat = best_weights[0]*yhat_lgb + best_weights[1]*yhat_rf\n",
    "    else:\n",
    "        yhat = yhat_lgb\n",
    "\n",
    "    step['Pred'] = np.clip(yhat, 0, None)  # non-negative\n",
    "    preds.append(step[['Key','YearWeek','Pred','yw_index']])\n",
    "\n",
    "    # Write predictions back into 'work' as if they were observed Sales to advance lags\n",
    "    idx = work['YearWeek'].eq(wk)\n",
    "    work.loc[idx, 'Sales'] = step['Pred'].values\n",
    "\n",
    "    # Rebuild lags/rolls/ewm for future weeks\n",
    "    work = work.sort_values(['Key','yw_index'])\n",
    "    work = work.groupby('Key', group_keys=False).apply(make_lags)\n",
    "    work = work.groupby('Key', group_keys=False).apply(make_rolls)\n",
    "    work = work.groupby('Key', group_keys=False).apply(make_ewm)\n",
    "\n",
    "pred_df = pd.concat(preds, ignore_index=True)\n",
    "pred_df = pred_df.sort_values(['Key','yw_index'])\n",
    "print(\"Forecast rows:\", pred_df.shape)\n",
    "print(\"Weeks covered:\", pred_df['YearWeek'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bfcad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EVALUATION & EXPORT\n",
      "==================================================\n",
      "Validation (2022-41..45) WMAPE: 0.5387 | Accuracy: 0.4613 | Bias: 0.1272\n",
      "\n",
      "Validation weekly sums (sanity check):\n",
      "             Sales           Pred\n",
      "YearWeek                         \n",
      "2022-41   265160.0  207178.737454\n",
      "2022-42   232719.0  237227.966944\n",
      "2022-43   261467.0  241134.539897\n",
      "2022-44   252236.0  239431.807359\n",
      "2022-45   278212.0  219279.502823\n",
      "\n",
      "Ground-truth availability for forecast window: Σ|Sales| = 0.0\n",
      "Ground truth appears hidden (all zeros). Skipping 9-week WMAPE/Bias.\n",
      "Saved: predictions_2022-46_to_2023-02.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"EVALUATION & EXPORT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1) Proper evaluation on validation weeks only\n",
    "val_truth = valid[['Key','YearWeek','Sales']].copy()\n",
    "val_pred  = pd.DataFrame({'Key': valid['Key'], 'YearWeek': valid['YearWeek']})\n",
    "val_pred['Pred'] = va_pred  # from the LGB validation prediction\n",
    "if 'va_pred_rf' in globals():\n",
    "    # use ensemble if you trained RF and found best_weights\n",
    "    val_pred['Pred'] = best_weights[0]*va_pred + best_weights[1]*va_pred_rf\n",
    "\n",
    "val_eval = val_truth.merge(val_pred, on=['Key','YearWeek'], how='left')\n",
    "print_metrics(val_eval['Sales'].values, val_eval['Pred'].values, \"Validation (2022-41..45)\")\n",
    "\n",
    "print(\"\\nValidation weekly sums (sanity check):\")\n",
    "print(val_eval.groupby('YearWeek').agg(Sales=('Sales','sum'), Pred=('Pred','sum')))\n",
    "\n",
    "# 2) Final 9-week forecast: export only (do not evaluate against 'Sales' since they are zero placeholders)\n",
    "truth_9w = df[df['YearWeek'].isin(PRED_WEEKS)][['Key','YearWeek','Sales']].copy()\n",
    "sums_9w_truth = truth_9w['Sales'].abs().sum()\n",
    "print(f\"\\nGround-truth availability for forecast window: Σ|Sales| = {sums_9w_truth:.1f}\")\n",
    "if sums_9w_truth < 1e-6:\n",
    "    print(\"Ground truth appears hidden (all zeros). Skipping 9-week WMAPE/Bias.\")\n",
    "\n",
    "# Save predictions\n",
    "submission = pred_df[['Key','YearWeek','Pred']].rename(columns={'Pred':'Prediction'}).copy()\n",
    "submission = submission.sort_values(['Key','YearWeek'])\n",
    "submission.to_csv(\"predictions_2022-46_to_2023-02.csv\", index=False)\n",
    "print(\"Saved: predictions_2022-46_to_2023-02.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
